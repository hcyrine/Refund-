# -*- coding: utf-8 -*-
"""refund2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cYlyZZZwXwccMiun2CJNlExLeJ-ofi1m

#Step1 Import librairies and dataset
"""

# Commented out IPython magic to ensure Python compatibility.
# Load, explore and plot data
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator
# %matplotlib inline
# Train test split
from sklearn.model_selection import train_test_split
# Text pre-processing
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping
import re
# Modeling
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout, GlobalAveragePooling1D, Flatten, SpatialDropout1D, Bidirectional

!pip install nlpaug
import nlpaug.augmenter.word as naw

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

data=pd.read_excel('OUTPUT_FINAL.xlsx')

# rename the columns
data = data[['Reason','Status']]
data.head()

data.describe()

data.groupby('Status').describe().T

data.Status.unique()

for statut in data['Status']:
   data['Status']=data['Status'].replace(statut, statut.upper())
data['Reason']=data['Reason'].map(lambda x: str(x))
for reason in data['Reason']:
   data['Reason']=data['Reason'].replace(reason, reason.upper())
data.head()

"""#Step2: Data preprocessing

# Data annotation
"""

def annotate (message,statut):
  if (message.find('SECTOR') or message.find('SECTORS'!=-1)) and  message.find('ONLY')!=-1  :
    return('PARTIAL_REFUND')
  else:
    return(statut)



#data annotation
df1=pd.DataFrame({'Status':[annotate(data['Reason'][i], data['Status'][i]) for i in range(len(data))]})
data['Status']=df1['Status']
#data.head()
sns.countplot(data, x="Status")

data.groupby('Status').describe().T

"""# Data augmentation"""

aug = naw.ContextualWordEmbsAug(
    model_path='bert-base-uncased', action="insert")
text = "The quick brown fox jumps over the lazy dog ."
augmented_text = aug.augment(text)
print("Original:")
print(text)
print("Augmented Text:")
print(augmented_text)

df=data.loc[data['Status'] == 'PARTIAL_REFUND']
df=pd.DataFrame(df)
df.head()

for i in range(2):
  for reason  in df['Reason']:
    augmented_text = aug.augment(reason)
    l = [augmented_text, 'PARTIAL_REFUND']
    data.loc[len(data)] = l

sns.countplot(data, x="Status")

"""#Step 3. Visualize REFUNDED and  PARTIAL_REFUND  message using wordcloud

The next step is to visualize the most frequently occurring words in a given text using WordCloud.

**The WordCloud of the ‘REFUNDED’ STATUS:**
"""

comment_words = ''
stopwords = set(STOPWORDS)

df1=data.loc[data['Status'] == 'REFUNDED']
for val in df1.Reason:

    # typecaste each val to string
    val = str(val)

    # split the value
    tokens = val.split()

    # Converts each token into lowercase
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()

    comment_words += " ".join(tokens)+" "

refunded_status_cloud = WordCloud(width =520, height =260, stopwords = STOPWORDS, max_font_size = 50, background_color = "black", colormap = 'Pastel1').generate(comment_words)
plt.figure(figsize=(16,10))
plt.imshow(refunded_status_cloud, interpolation = 'bilinear')
plt.axis('off') # turn off axis
plt.show()

"""The words that appear most frequently in full refund status based on WordCloud above are: full refund, per ticket, approval code etc.

**The WordCloud of the ‘PARTIAL_REFUND’ status**
"""

comment_words = ''
stopwords = set(STOPWORDS)

df3=data.loc[data['Status'] == 'PARTIAL_REFUND']
for val in df3.Reason:

    # typecaste each val to string
    val = str(val)

    # split the value
    tokens = val.split()

    # Converts each token into lowercase
    for i in range(len(tokens)):
        tokens[i] = tokens[i].lower()

    comment_words += " ".join(tokens)+" "

partial_status_cloud = WordCloud(width =520, height =260, stopwords = STOPWORDS, max_font_size = 50, background_color = "black", colormap = 'Pastel1').generate(comment_words)
plt.figure(figsize=(16,10))
plt.imshow(partial_status_cloud, interpolation = 'bilinear')
plt.axis('off') # turn off axis
plt.show()

"""The words that appear most frequently in PARTIAL refund status based on WordCloud above are: refund, ticket, approval code, sector etc.

#Step 4. Text preprocessing
"""

data['Reason'] = data['Reason'].apply(lambda x: str(x).lower())
data['Reason'] = data['Reason'].apply((lambda x: re.sub('[^a-zA-z0-9\s]','',x)))


for idx,row in data.iterrows():
    row[0] = row[0].replace('rt',' ')

max_fatures = 2000
tokenizer = Tokenizer(num_words=max_fatures, split=' ')
tokenizer.fit_on_texts(data['Reason'].values)
X = tokenizer.texts_to_sequences(data['Reason'].values)
seq_max_len=50
X = pad_sequences(X, maxlen=seq_max_len)

"""**post-training**"""

import pickle

# Saving the models and the Count Vectorizer converter in a pkl file so that it can
# be used in another program without trainig the models.
tokenizer_pkl_file = "tok_model.pkl"

with open(tokenizer_pkl_file, 'wb') as file:
    pickle.dump(tokenizer, file)

"""# TRAINING THE MODELS

Train test split

we do a train test split to divide the data into 66.66% train data and 33.33% test data.
"""

print(pd.get_dummies(data['Status']).head())
Y = pd.get_dummies(data['Status']).values
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)
print(X_train.shape,Y_train.shape)
print(X_test.shape,Y_test.shape)

"""**LSTM MODEL**"""

embed_dim = 128
lstm_out = 196

model = Sequential()
model.add(Embedding(max_fatures, embed_dim))
model.add(SpatialDropout1D(0.6))
model.add(LSTM(lstm_out, dropout=0.7, recurrent_dropout=0.5))
model.add(Dense(2,activation='softmax'))
model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])
print(model.summary())

Y_test

batch_size = 32
model.fit(X_train, Y_train, epochs = 2, batch_size=batch_size, verbose = 2)

validation_size = 1500

X_validate = X_test[-validation_size:]
Y_validate = Y_test[-validation_size:]
X_test = X_test[:-validation_size]
Y_test = Y_test[:-validation_size]
score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)
print("score: %.2f" % (score))
print("acc: %.2f" % (acc))

import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# get the model’s prediction for the test set
predictions = model.predict(X_test)
# Convert predictions to class labels
predicted_labels = np.argmax(predictions, axis=1)  # Assuming predictions are probabilities
print(len(X_test))

# using the model’s prediction and the true value,
# create a confusion matrix
cm = confusion_matrix(np.argmax(Y_test, axis=1), predicted_labels) # Convert Y_test to class labels




# use the built-in visualization function to generate a plot
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

"""the model does a good job at predicting the full refund and partial refund cases

**Bidirectional LSTM**
"""

embed_dim = 128
lstm_out = 196

model1 = Sequential()
model1.add(Embedding(max_fatures, embed_dim))
model1.add(SpatialDropout1D(0.4))
model1.add(Bidirectional(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2)))
model1.add(Dense(2,activation='softmax'))
model1.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])
print(model1.summary())

Y_test

batch_size = 32
model1.fit(X_train, Y_train, epochs = 2, batch_size=batch_size, verbose = 2)

"""**post training**"""

# Saving the models and the Count Vectorizer converter in a pkl file so that it can
# be used in another program without trainig the models.
model_pkl_file = "model.pkl"

with open(model_pkl_file, 'wb') as file:
    pickle.dump(model1, file)

import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# get the model’s prediction for the test set
predictions = model1.predict(X_test)
# Convert predictions to class labels
predicted_labels = np.argmax(predictions, axis=1)  # Assuming predictions are probabilities
print(len(X_test))

# using the model’s prediction and the true value,
# create a confusion matrix
cm = confusion_matrix(np.argmax(Y_test, axis=1), predicted_labels) # Convert Y_test to class labels




# use the built-in visualization function to generate a plot
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

validation_size = 1500

X_validate = X_test[-validation_size:]
Y_validate = Y_test[-validation_size:]
X_test = X_test[:-validation_size]
Y_test = Y_test[:-validation_size]
score,acc = model1.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)
print("score: %.2f" % (score))
print("acc: %.2f" % (acc))

test_sequence = tokenizer.texts_to_sequences(['full refund due to flight cancelation'])
padded_sequence = pad_sequences(test_sequence, maxlen=50)

model1.predict(padded_sequence)

"""#GRU Model"""

embed_dim = 128
lstm_out = 196
max_len=520
# Assuming you have a tokenizer object named 'tokenizer'
vocab_size = len(tokenizer.word_index) + 1  # +1 for the padding token

model2 = Sequential()
model2.add(Embedding(vocab_size,  # Use the correct vocabulary size here
                     embed_dim,
                     input_length = max_len))
model2.add(SpatialDropout1D(0.2))
model2.add(GRU(128, return_sequences = False))
model2.add(Dropout(0.2))
model2.add(Dense(2, activation = 'softmax'))
model2.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])
print(model2.summary())

Y_test

batch_size = 32
model2.fit(X_train, Y_train, epochs = 2, batch_size=batch_size, verbose = 2)

validation_size = 1500

X_validate = X_test[-validation_size:]
Y_validate = Y_test[-validation_size:]
X_test = X_test[:-validation_size]
Y_test = Y_test[:-validation_size]
score,acc = model2.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)
print("score: %.2f" % (score))
print("acc: %.2f" % (acc))

import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# get the model’s prediction for the test set
predictions = model2.predict(X_test)
# Convert predictions to class labels
predicted_labels = np.argmax(predictions, axis=1)  # Assuming predictions are probabilities
print(len(X_test))

# using the model’s prediction and the true value,
# create a confusion matrix
cm = confusion_matrix(np.argmax(Y_test, axis=1), predicted_labels) # Convert Y_test to class labels




# use the built-in visualization function to generate a plot
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

"""Bidirectional LSTM and GRU have the same accuracy

"""